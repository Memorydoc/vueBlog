(window.webpackJsonp=window.webpackJsonp||[]).push([[39],{312:function(t,s,a){"use strict";a.r(s);var n=a(10),e=Object(n.a)({},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"图片基础与tf-keras介绍"}},[t._v("图片基础与tf.keras介绍")]),t._v(" "),a("ul",[a("li",[t._v("目标\n"),a("ul",[a("li",[t._v("说明图片数字化的三要素")]),t._v(" "),a("li",[t._v("说明图片三要素与张量的表示关系")]),t._v(" "),a("li",[t._v("说明tf.keras 图片读取API使用")]),t._v(" "),a("li",[t._v("说明NHWC与NCHW的区别")])])]),t._v(" "),a("li",[t._v("应用\n"),a("ul",[a("li",[t._v("无")])])])]),t._v(" "),a("h2",{attrs:{id:"图像基本知识"}},[t._v("图像基本知识")]),t._v(" "),a("p",[t._v("回忆：之前我们在特征抽取中讲过如何将文本处理成数值。")]),t._v(" "),a("p",[a("strong",[t._v("思考：如何将图片文件转换成机器学习算法能够处理的数据？")])]),t._v(" "),a("p",[t._v("我们经常接触到的图片有两种，一种是黑白图片（灰度图），另一种是彩色图片。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/articial/%E9%BB%91%E7%99%BD%E5%BD%A9%E8%89%B2.png",alt:"黑白彩色"}})]),t._v(" "),a("ul",[a("li",[t._v("组成图片的最基本单位是像素。")])]),t._v(" "),a("h3",{attrs:{id:"_2-1-1-1-图片三要素"}},[t._v("2.1.1.1 图片三要素")]),t._v(" "),a("p",[t._v("组成一张图片特征值是所有的像素值，有三个维度："),a("strong",[t._v("图片长度、图片宽度、图片通道数")]),t._v("。")]),t._v(" "),a("p",[t._v("图片的通道数是什么？")]),t._v(" "),a("p",[t._v("描述一个像素点，如果是灰度图，那么只需要一个数值来描述它，就是单通道。")]),t._v(" "),a("p",[t._v("如果一个像素点，有RGB三种颜色来描述它，就是三通道。")]),t._v(" "),a("ul",[a("li",[t._v("灰度图：单通道")]),t._v(" "),a("li",[t._v("彩色图片：三通道")])]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/articial/%E9%80%9A%E9%81%93%E6%95%B0.png",alt:"通道数"}})]),t._v(" "),a("blockquote",[a("p",[t._v("假设一张彩色图片的长200，宽200，通道数为3，那么总的像素数量为200 * 200 * 3")])]),t._v(" "),a("h3",{attrs:{id:"张量形状"}},[t._v("张量形状")]),t._v(" "),a("p",[t._v("在TensorFlow中如何用张量表示一张图片呢？")]),t._v(" "),a("p",[t._v("一张图片可以被表示成一个3D张量，即其形状为[height, width, channel]，height就表示高，width表示宽，channel表示通道数。我们会经常遇到3D和4D的表示")]),t._v(" "),a("ul",[a("li",[t._v("单个图片：[height, width, channel]")]),t._v(" "),a("li",[t._v("多个图片：[batch,height, width, channel]，batch表示一个批次的张量数量")])]),t._v(" "),a("h2",{attrs:{id:"tf-keras介绍"}},[t._v("tf.keras介绍")]),t._v(" "),a("p",[t._v("Keras是一个用Python编写的开源神经网络库。它能够运行在TensorFlow，Microsoft Cognitive Toolkit，Theano或PlaidML之上。TensorFlow 1.9 新增 tf.keras,Keras与TF的深度集成。")]),t._v(" "),a("h3",{attrs:{id:"为什么选择-keras？"}},[t._v("为什么选择 Keras？")]),t._v(" "),a("p",[t._v("在如今无数深度学习框架中，为什么要使用 Keras 而非其他？以下是 Keras 与现有替代品的一些比较。")]),t._v(" "),a("ul",[a("li",[t._v("Keras 遵循减少认知困难的最佳实践: 它提供一致且简单的 API，它将常见用例所需的用户操作数量降至最低，并且在用户错误时提供清晰和可操作的反馈。")]),t._v(" "),a("li",[t._v("因为 Keras 与底层深度学习语言（特别是 TensorFlow）集成在一起，所以它可以让你实现任何你可以用基础语言编写的东西。特别是，"),a("code",[t._v("tf.keras")]),t._v(" 作为 Keras API 可以与 TensorFlow 工作流无缝集成。")])]),t._v(" "),a("ul",[a("li",[t._v("Keras 被工业界和学术界广泛采用")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://s3.amazonaws.com/keras.io/img/dl_frameworks_power_scores.png",alt:"img"}})]),t._v(" "),a("p",[t._v("截至 2018 年中期，Keras 拥有超过 250,000 名个人用户。与其他任何深度学习框架相比，Keras 在行业和研究领域的应用率更高（除 TensorFlow 之外，且 Keras API 是 TensorFlow 的官方前端，通过 "),a("code",[t._v("tf.keras")]),t._v(" 模块使用）。")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("Keras 拥有强大的多 GPU 和分布式训练支持")]),t._v(" "),a("ul",[a("li",[t._v("Keras内置对多 GPU 数据并行的支持。")])])]),t._v(" "),a("li",[a("p",[t._v("Keras 的发展得到深度学习生态系统中的关键公司的支持")])])]),t._v(" "),a("p",[t._v("Keras API 以 "),a("code",[t._v("tf.keras")]),t._v(" 的形式包装在 TensorFlow 中。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://keras.io/img/google-logo.png",alt:"img"}})]),t._v(" "),a("h2",{attrs:{id:"tf-keras与keras-api"}},[t._v("tf.keras与keras API")]),t._v(" "),a("p",[t._v("keras与tf.keras相关API设置一样，主要有以下常用模块")]),t._v(" "),a("ul",[a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/applications",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("applications")]),a("OutboundLink")],1),t._v(" 模块：Keras应用程序是具有预训练权重的固定架构。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("callbacks")]),a("OutboundLink")],1),t._v(" module：回调：在模型训练期间在某些点调用的实用程序。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/datasets",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("datasets")]),a("OutboundLink")],1),t._v(" module：Keras内置数据集。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/initializers",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("initializers")]),a("OutboundLink")],1),t._v(" 模块：Keras初始化器序列化/反序列化。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/layers",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("layers")]),a("OutboundLink")],1),t._v(" 模块：Keras层API。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/losses",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("losses")]),a("OutboundLink")],1),t._v(" 模块：内置损失功能。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/metrics",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("metrics")]),a("OutboundLink")],1),t._v(" 模块：内置指标。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/models",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("models")]),a("OutboundLink")],1),t._v(" module：模型克隆代码，以及与模型相关的API。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("optimizers")]),a("OutboundLink")],1),t._v(" module：内置优化器类。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("preprocessing")]),a("OutboundLink")],1),t._v(" 模块：Keras数据预处理工具。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/regularizers",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("regularizers")]),a("OutboundLink")],1),t._v(" 模块：内置正规化器。")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/utils",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("utils")]),a("OutboundLink")],1),t._v(" 模块：Keras实用程序。")])])]),t._v(" "),a("h2",{attrs:{id:"图片读取处理"}},[t._v("图片读取处理")]),t._v(" "),a("h3",{attrs:{id:"tensorflow-python-keras-preprocessing-image"}},[t._v("tensorflow.python.keras.preprocessing.image")]),t._v(" "),a("p",[t._v("image模块提供了读取图片处理的API")]),t._v(" "),a("p",[t._v("要使用该模块需要下载图片读取库")]),t._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("pip install Pillow\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br")])]),a("ul",[a("li",[t._v("load_img(path=filepath, target_size)：加载图片")])]),t._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('image = load_img("./bus/300.jpg")\nprint(image)\n\n<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x256 at 0x10E51D6D8>\n')])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br")])]),a("p",[t._v("返回一个PIL.JpegImagePlugin.JpegImageFile对象。")]),t._v(" "),a("p",[a("strong",[t._v("图片特征值处理")]),t._v("-图片大小")]),t._v(" "),a("p",[t._v("为什么要"),a("strong",[t._v("缩放")]),t._v("图片到"),a("strong",[t._v("统一大小")]),t._v("？")]),t._v(" "),a("p",[t._v("在进行图像识别的时候，每个图片样本的特征数量要保持相同。所以需要将所有图片张量大小统一转换。")]),t._v(" "),a("p",[t._v("另一方面，如果图片的像素量太大，通过这种方式适当减少像素的数量，减少训练的计算开销。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("image "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" load_img"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./bus/300.jpg"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target_size"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("PIL"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Image"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Image image mode"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("RGB size"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("200x200 at "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0x1082A06A0")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("p",[t._v("由于读取出来的类型不能直接在TensorFlow中使用，所以需要进行类型转换")]),t._v(" "),a("ul",[a("li",[t._v("img_to_array(img, data_format=None, dtype=None):：图片转换成数组格式\n"),a("ul",[a("li",[t._v("img: PIL Image instance.")]),t._v(" "),a("li",[t._v('data_format: Image data format,either "channels_first" or "channels_last".')]),t._v(" "),a("li",[t._v("dtype: Dtype to use for the returned array.")])])])]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("image "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img_to_array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("image"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("image"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("p",[t._v("打印出来图片的数组值")]),t._v(" "),a("h3",{attrs:{id:"nhwc与nchw"}},[t._v("NHWC与NCHW")]),t._v(" "),a("p",[t._v('在读取设置图片形状的时候有两种格式"channels_first" or "channels_last".：')]),t._v(" "),a("p",[a("strong",[t._v('设置为 "NHWC" 时，排列顺序为 [batch, height, width, channels]；')])]),t._v(" "),a("p",[a("strong",[t._v('设置为 "NCHW" 时，排列顺序为 [batch, channels, height, width]。')])]),t._v(" "),a("p",[t._v("其中 N 表示这批图像有几张，H 表示图像在竖直方向有多少像素，W 表示水平方向像素数，C 表示通道数。")]),t._v(" "),a("p",[a("strong",[t._v("Tensorflow默认的[height, width, channel]")])]),t._v(" "),a("p",[t._v("假设RGB三通道两种格式的区别如下图所示：")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/articial/NCHW%E4%B8%8ENWHC.png",alt:""}})]),t._v(" "),a("ul",[a("li",[t._v("理解")])]),t._v(" "),a("p",[t._v("假设1, 2, 3, 4-红色       5, 6, 7, 8-绿色      9, 10, 11, 12-蓝色")]),t._v(" "),a("ul",[a("li",[t._v("如果通道在最低维度0[channel, height, width]，RGB三颜色分成三组，在第一维度上找到三个RGB颜色")]),t._v(" "),a("li",[t._v("如果通道在最高维度2[height, width, channel]，在第三维度上找到RGB三个颜色")])]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/articial/%E7%BB%B4%E5%BA%A6%E7%B4%A2%E5%BC%951.png",alt:"维度索引1"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/articial/%E7%BB%B4%E5%BA%A6%E7%B4%A2%E5%BC%952.png",alt:"维度索引2"}})]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1、想要变成：[2 height, 2width,  3channel]，但是输出结果不对")]),t._v("\nIn "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nOut"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\narray"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("int32"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2、所以要这样去做")]),t._v("\nIn "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nOut"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\narray"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("int32"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 接着使用tf.transpose ，0，1，2代表三个维度标记")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Convert from [depth, height, width] to [height, width, depth].")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0,1,2-----\x3e 1, 2, 0")]),t._v("\nIn "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transpose"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("depth_major"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nOut"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\narray"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("int32"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br"),a("span",{staticClass:"line-number"},[t._v("29")]),a("br"),a("span",{staticClass:"line-number"},[t._v("30")]),a("br")])]),a("ul",[a("li",[t._v("转换API")])]),t._v(" "),a("ul",[a("li",[t._v("tf.transpose(a, perm=None)\n"),a("ul",[a("li",[t._v("Transposes "),a("code",[t._v("a")]),t._v(". Permutes the dimensions according to "),a("code",[t._v("perm")]),t._v(".\n"),a("ul",[a("li",[t._v("修改维度的位置")])])]),t._v(" "),a("li",[t._v("a：数据")]),t._v(" "),a("li",[t._v("perm:形状的维度值下标列表")])])])]),t._v(" "),a("ul",[a("li",[t._v("处理图片的形状")])]),t._v(" "),a("p",[t._v("所以在读取数据处理形状的时候")]),t._v(" "),a("ul",[a("li",[t._v("1 image (3072, ) —>tf.reshape(image, [])里面的shape是[channel, height, width]， "),a("strong",[t._v("所以得先从[depth * height * width] to [depth, height, width]")]),t._v("。")]),t._v(" "),a("li",[t._v("2 然后使用tf.transpose， 将刚才的数据[depth, height, width]，变成Tensorflow默认的[height, width, channel]")])]),t._v(" "),a("h2",{attrs:{id:"tf-keras-数据集"}},[t._v("tf.keras 数据集")]),t._v(" "),a("h3",{attrs:{id:"cifar10-小图片分类数据"}},[t._v("CIFAR10 小图片分类数据")]),t._v(" "),a("p",[t._v("50000张32x32大小的训练数据和10000张测试数据，总共100个类别。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datasets "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" cifar100\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cifar100"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("ul",[a("li",[t._v("返回值：\n"),a("ul",[a("li",[t._v("两个元组:\n"),a("ul",[a("li",[a("strong",[t._v("x_train, x_test")]),t._v(": uint8 数组表示的 RGB 图像数据，尺寸为 (num_samples, 3, 32, 32) 或 (num_samples, 32, 32, 3)，基于 "),a("code",[t._v("image_data_format")]),t._v(" 后端设定的 "),a("code",[t._v("channels_first")]),t._v(" 或 "),a("code",[t._v("channels_last")]),t._v("。")]),t._v(" "),a("li",[a("strong",[t._v("y_train, y_test")]),t._v(": uint8 数组表示的类别标签，尺寸为 (num_samples,)。")])])])])])]),t._v(" "),a("h3",{attrs:{id:"时装分类mnist数据集"}},[t._v("时装分类Mnist数据集")]),t._v(" "),a("p",[t._v("60,000张28x28总共10个类别的灰色图片，10,000张用于测试。")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("类别编号")]),t._v(" "),a("th",[t._v("类别")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("0")]),t._v(" "),a("td",[t._v("T-shirt/top")])]),t._v(" "),a("tr",[a("td",[t._v("1")]),t._v(" "),a("td",[t._v("Trouser")])]),t._v(" "),a("tr",[a("td",[t._v("2")]),t._v(" "),a("td",[t._v("Pullover")])]),t._v(" "),a("tr",[a("td",[t._v("3")]),t._v(" "),a("td",[t._v("Dress")])]),t._v(" "),a("tr",[a("td",[t._v("4")]),t._v(" "),a("td",[t._v("Coat")])]),t._v(" "),a("tr",[a("td",[t._v("5")]),t._v(" "),a("td",[t._v("Sandal")])]),t._v(" "),a("tr",[a("td",[t._v("6")]),t._v(" "),a("td",[t._v("Shirt")])]),t._v(" "),a("tr",[a("td",[t._v("7")]),t._v(" "),a("td",[t._v("Sneaker")])]),t._v(" "),a("tr",[a("td",[t._v("8")]),t._v(" "),a("td",[t._v("Bag")])]),t._v(" "),a("tr",[a("td",[t._v("9")]),t._v(" "),a("td",[t._v("Ankle boot")])])])]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datasets "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" fashion_mnist\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fashion_mnist"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("ul",[a("li",[t._v("返回两个元组:\n"),a("ul",[a("li",[a("strong",[t._v("x_train, x_test")]),t._v(": uint8 数组表示的灰度图像，尺寸为 (num_samples, 28, 28)。")]),t._v(" "),a("li",[a("strong",[t._v("y_train, y_test")]),t._v(": uint8 数组表示的数字标签（范围在 0-9 之间的整数），尺寸为 (num_samples,)。")])])])])])},[],!1,null,null,null);s.default=e.exports}}]);