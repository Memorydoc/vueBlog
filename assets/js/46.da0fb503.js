(window.webpackJsonp=window.webpackJsonp||[]).push([[46],{319:function(v,_,i){"use strict";i.r(_);var l=i(10),t=Object(l.a)({},function(){var v=this,_=v.$createElement,i=v._self._c||_;return i("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[i("h1",{attrs:{id:"卷积神经网络-cnn-原理"}},[v._v("卷积神经网络(CNN)原理")]),v._v(" "),i("h2",{attrs:{id:"学习目标"}},[v._v("学习目标")]),v._v(" "),i("ul",[i("li",[v._v("目标\n"),i("ul",[i("li",[v._v("了解卷积神经网络的构成")]),v._v(" "),i("li",[v._v("记忆卷积的原理以及计算过程")]),v._v(" "),i("li",[v._v("了解池化的作用以及计算过程")])])]),v._v(" "),i("li",[v._v("应用\n"),i("ul",[i("li",[v._v("无")])])])]),v._v(" "),i("h3",{attrs:{id:"卷积神经网络的组成"}},[v._v("卷积神经网络的组成")]),v._v(" "),i("ul",[i("li",[v._v("定义\n"),i("ul",[i("li",[v._v("卷积神经网络由"),i("strong",[v._v("一个或多个卷积层、池化层以及全连接层等组成")]),v._v("。与其他深度学习结构相比，卷积神经网络在图像等方面能够给出更好的结果。这一模型也可以使用"),i("strong",[v._v("反向传播算法")]),v._v("进行训练。相比较其他浅层或深度神经网络，卷积神经网络需要考量的参数更少，使之成为一种颇具吸引力的深度学习结构。")])])])]),v._v(" "),i("p",[v._v("我们来看一下卷积网络的整体结构什么样子。")]),v._v(" "),i("p",[i("img",{attrs:{src:"/img/articial/%E7%BB%8F%E5%85%B8%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%BB%93%E6%9E%84.png",alt:""}})]),v._v(" "),i("p",[v._v("其中包含了几个主要结构")]),v._v(" "),i("ul",[i("li",[i("strong",[v._v("卷积层（Convolutions）")])]),v._v(" "),i("li",[i("strong",[v._v("池化层（Subsampling）")])]),v._v(" "),i("li",[v._v("全连接层（Full connection）")]),v._v(" "),i("li",[v._v("激活函数")])]),v._v(" "),i("h3",{attrs:{id:"卷积层"}},[v._v("卷积层")]),v._v(" "),i("ul",[i("li",[v._v("目的\n"),i("ul",[i("li",[v._v("卷积运算的目的是提取输入的不同特征，某些卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网路能从低级特征中迭代提取更复杂的特征。")])])]),v._v(" "),i("li",[v._v("参数：\n"),i("ul",[i("li",[v._v("size:卷积核/过滤器大小，"),i("strong",[v._v("选择有1 * 1， 3 * 3， 5 * 5")]),v._v("（为什么是奇数个）")]),v._v(" "),i("li",[v._v("padding："),i("strong",[v._v("零填充，Valid 与Same")])]),v._v(" "),i("li",[v._v("stride:步长，"),i("strong",[v._v("通常默认为1")])])])]),v._v(" "),i("li",[v._v("计算公式")])]),v._v(" "),i("p",[i("img",{attrs:{src:"/img/articial/%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F.png",alt:""}})]),v._v(" "),i("h4",{attrs:{id:"卷积运算过程"}},[v._v("卷积运算过程")]),v._v(" "),i("p",[v._v("对于之前介绍的卷积运算过程，我们用一张动图来表示更好理解些。一下计算中，假设图片长宽相等，设为N")]),v._v(" "),i("ul",[i("li",[v._v("一个步长，3 X 3 卷积核运算")])]),v._v(" "),i("p",[v._v("假设是一张5 X 5 的单通道图片，通过使用3 X 3 大小的卷积核运算得到一个 3 X 3大小的运算结果（图片像素数值仅供参考）")]),v._v(" "),i("p",[i("img",{attrs:{src:"/img/articial/%E5%8D%95%E4%B8%AA%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%A7%BB%E5%8A%A8%E6%AD%A5%E9%95%BF.gif",alt:""}})]),v._v(" "),i("p",[v._v("我们会发现进行卷积之后的图片变小了，假设N为图片大小，F为卷积核大小")]),v._v(" "),i("p",[v._v("相当于$$N - F  + 1 = 5 - 3 + 1 = 3$$")]),v._v(" "),i("p",[v._v("如果我们换一个卷积核大小或者加入很多层卷积之后，图像可能最后就变成了1 X 1 大小，这不是我们希望看到的结果。并且对于原始图片当中的边缘像素来说，只计算了一遍，二对于中间的像素会有很多次过滤器与之计算，这样导致对边缘信息的丢失。")]),v._v(" "),i("ul",[i("li",[v._v("缺点\n"),i("ul",[i("li",[v._v("图像变小")]),v._v(" "),i("li",[v._v("边缘信息丢失")])])])]),v._v(" "),i("h3",{attrs:{id:"padding-零填充"}},[v._v("padding-零填充")]),v._v(" "),i("p",[v._v("零填充：在图片像素的最外层加上若干层0值，若一层，记做p =1。")]),v._v(" "),i("ul",[i("li",[v._v("为什么增加的是0？")])]),v._v(" "),i("p",[v._v("因为0在权重乘积和运算中对最终结果不造成影响，也就避免了图片增加了额外的干扰信息。")]),v._v(" "),i("p",[i("img",{attrs:{src:"/img/articial/%E9%9B%B6%E5%A1%AB%E5%85%85%E4%B8%80%E5%B1%82.png",alt:""}})]),v._v(" "),i("p",[v._v("这张图中，还是移动一个像素，并且外面增加了一层0。那么最终计算结果我们可以这样用公式来计算：")]),v._v(" "),i("p",[v._v("$$5 + 2 * p - 3 + 1 = 5$$")]),v._v(" "),i("p",[v._v("P为1，那么最终特征结果为5。实际上我们可以填充更多的像素，假设为2层，则")]),v._v(" "),i("p",[i("strong",[v._v("$$5 + 2 * 2 - 3 + 1 = 7$$，这样得到的观察特征大小比之前图片大小还大。所以我们对于零填充会有一些选择，该填充多少？")])]),v._v(" "),i("h4",{attrs:{id:"valid-and-same卷积"}},[v._v("Valid and Same卷积")]),v._v(" "),i("p",[v._v("有两种两种形式，所以为了避免上述情况，大家选择都是Same这种填充卷积计算方式")]),v._v(" "),i("ul",[i("li",[v._v("Valid :不填充，也就是最终大小为\n"),i("ul",[i("li",[v._v("$$(N - F + 1) * (N - F + 1)$$")])])]),v._v(" "),i("li",[v._v("Same：输出大小与原图大小一致，那么 $$N$$变成了$$N + 2P$$\n"),i("ul",[i("li",[v._v("$$(N + 2P - F + 1) * (N + 2P - F + 1)$$")])])])]),v._v(" "),i("p",[v._v("那也就意味着，之前大小与之后的大小一样，得出下面的等式")]),v._v(" "),i("p",[v._v("$$(N + 2P - F + 1)  = N$$")]),v._v(" "),i("p",[v._v("$$P = \\frac{F -1}{2}$$")]),v._v(" "),i("p",[v._v("所以当知道了卷积核的大小之后，就可以得出要填充多少层像素。")]),v._v(" "),i("h4",{attrs:{id:"奇数维度的过滤器"}},[v._v("奇数维度的过滤器")]),v._v(" "),i("p",[v._v("通过上面的式子，如果F不是奇数而是偶数个，那么最终计算结果不是一个整数，"),i("strong",[v._v("造成0.5,1.5.....这种情况，这样填充不均匀，所以也就是为什么卷积核默认都去使用奇数维度大小")])]),v._v(" "),i("ul",[i("li",[i("p",[v._v("1 x 1，3 x 3， 5 x 5，7 x 7")])]),v._v(" "),i("li",[i("p",[v._v("另一个解释角度")]),v._v(" "),i("ul",[i("li",[v._v("奇数维度的过滤器有中心，便于指出过滤器的位置")])])])]),v._v(" "),i("p",[v._v("当然这个都是一些假设的原因，最终原因还是在F对于计算结果的影响。所以通常选择奇数维度的过滤器，是大家约定成俗的结果，可能也是基于大量实验奇数能得出更好的结果。")]),v._v(" "),i("h3",{attrs:{id:"stride-步长"}},[v._v("stride-步长")]),v._v(" "),i("p",[v._v("以上例子中我们看到的都是每次移动一个像素步长的结果，如果将这个步长修改为2,3，那结果如何？")]),v._v(" "),i("p",[i("img",{attrs:{src:"/img/articial/%E6%AD%A5%E9%95%BF%E4%B8%BA2%E7%9A%84%E7%BB%93%E6%9E%9C.png",alt:""}})]),v._v(" "),i("p",[v._v("这样如果以原来的计算公式，那么结果")]),v._v(" "),i("p",[v._v("$$N + 2P - F + 1 = 6 + 0 -3 +1 = 4$$")]),v._v(" "),i("p",[v._v("但是移动2个像素才得出一个结果，所以公式变为")]),v._v(" "),i("p",[v._v("$$\\frac{N + 2P - F}{2} + 1 = 1.5 + 1 = 2.5$$，如果相除不是整数的时候，向下取整，为2。这里并没有加上零填充。")]),v._v(" "),i("p",[v._v("所以最终的公式就为：")]),v._v(" "),i("p",[v._v("对于输入图片大小为N，过滤器大小为F，步长为S，零填充为P，")]),v._v(" "),i("p",[v._v("$$(\\frac{N + 2P - F}{S} + 1),(\\frac{N + 2P - F}{S} + 1)$$")]),v._v(" "),i("h3",{attrs:{id:"多通道卷积"}},[v._v("多通道卷积")]),v._v(" "),i("p",[v._v("当输入有多个通道（channel）时(例如图片可以有 RGB 三个通道)，卷积核需要拥有相同的channel数,每个卷积核 channel 与输入层的对应 channel 进行卷积，将每个 channel 的卷积结果按位相加得到最终的 Feature Map。")]),v._v(" "),i("p",[i("img",{attrs:{src:"/img/articial/%E5%A4%9A%E9%80%9A%E9%81%93%E5%8D%B7%E7%A7%AF.png",alt:""}})]),v._v(" "),i("h4",{attrs:{id:"多卷积核（多个filter）"}},[v._v("多卷积核（多个Filter）")]),v._v(" "),i("p",[v._v("当有多个卷积核时，可以学习到多种不同的特征，对应产生包含多个 channel 的 Feature Map, 例如上图有两个 filter，所以 output 有两个 channel。"),i("strong",[v._v("这里的多少个卷积核也可理解为多少个神经元。")])]),v._v(" "),i("p",[i("img",{attrs:{src:"/img/articial/%E5%A4%9A%E5%8D%B7%E7%A7%AF%E6%A0%B8.png",alt:""}})]),v._v(" "),i("p",[v._v("相当于我们把多个功能的卷积核的计算结果放在一起，能够检测到图片中不同的特征（边缘检测）")]),v._v(" "),i("h3",{attrs:{id:"卷积总结"}},[v._v("卷积总结")]),v._v(" "),i("p",[v._v("我们来通过一个例子看一下结算结果，以及参数的计算")]),v._v(" "),i("ul",[i("li",[v._v("假设我们有10 个Filter，每个Filter3 X 3 X 3（计算RGB图片），并且只有一层卷积，那么参数有多少？")])]),v._v(" "),i("p",[v._v("计算：每个Filter参数个数为：3 * 3 * 3 + 1 bias = 28个权重参数，总共28 * 10 = 280个参数，即使图片任意大小，我们这层的参数也就这么多。")]),v._v(" "),i("ul",[i("li",[v._v("假设一张200 * 200 * 3的图片，进行刚才的FIlter,步长为1，最终为了保证最后输出的大小为200 * 200，需要设置多大的零填充")])]),v._v(" "),i("p",[v._v("$$(\\frac{N + 2P - F}{s} + 1)  = N$$")]),v._v(" "),i("p",[v._v("$$P = \\frac{(N -1) * s + F - N}{2} = \\frac{199 + 3 - 200}{2} = 1$$")]),v._v(" "),i("p",[i("strong",[v._v("卷积层充当特征提取的角色，但是并没有减少图片的特征数量，在最后的全连接层依然面临大量的参数，所以需要池化层进行特征数量的减少")])]),v._v(" "),i("h3",{attrs:{id:"池化层-pooling"}},[v._v("池化层(Pooling)")]),v._v(" "),i("p",[v._v("池化层主要对卷积层学习到的特征图进行亚采样（subsampling）处理，主要由两种")]),v._v(" "),i("ul",[i("li",[i("strong",[v._v("最大池化：Max Pooling,取窗口内的最大值作为输出")])]),v._v(" "),i("li",[v._v("平均池化：Avg Pooling,取窗口内的所有值的均值作为输出")])]),v._v(" "),i("p",[v._v("意义在于：")]),v._v(" "),i("ul",[i("li",[v._v("降低了后续网络层的输入维度，缩减模型大小，提高计算速度")]),v._v(" "),i("li",[i("strong",[v._v("提高了Feature Map 的鲁棒性，防止过拟合")])])]),v._v(" "),i("p",[i("img",{attrs:{src:"/img/articial/%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96.png",alt:""}})]),v._v(" "),i("p",[v._v("对于一个输入的图片，我们使用一个区域大小为2 * 2，步长为2的参数进行求最大值操作。同样池化也有一组参数，$$f, s$$，得到2 * 2的大小。当然如果我们调整这个超参数，比如说3 * 3，那么结果就不一样了，通常选择默认都是$$f = 2 * 2, s = 2$$")]),v._v(" "),i("p",[v._v("池化超参数特点：不需要进行学习，不像卷积通过梯度下降进行更新。")]),v._v(" "),i("p",[v._v("如果是平均池化则：")]),v._v(" "),i("p",[i("img",{attrs:{src:"/img/articial/%E5%B9%B3%E5%9D%87%E6%B1%A0%E5%8C%96.png",alt:""}})]),v._v(" "),i("h3",{attrs:{id:"全连接层"}},[v._v("全连接层")]),v._v(" "),i("p",[v._v("卷积层+激活层+池化层可以看成是CNN的特征学习/特征提取层，而学习到的特征（Feature Map）最终应用于模型任务（分类、回归）：")]),v._v(" "),i("ul",[i("li",[v._v("先对所有 Feature Map 进行扁平化（flatten, 即 reshape 成 1 x N 向量）")]),v._v(" "),i("li",[v._v("再接一个或多个全连接层，进行模型学习")])]),v._v(" "),i("p",[i("img",{attrs:{src:"/img/articial/%E5%8A%A0%E5%85%A5%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82.png",alt:""}})]),v._v(" "),i("h3",{attrs:{id:"总结"}},[v._v("总结")]),v._v(" "),i("ul",[i("li",[v._v("掌握卷积神经网路的组成")]),v._v(" "),i("li",[v._v("掌握卷积的计算过程\n"),i("ul",[i("li",[v._v("卷积过滤器个数")]),v._v(" "),i("li",[v._v("卷积过滤器大小")]),v._v(" "),i("li",[v._v("卷积过滤器步数")]),v._v(" "),i("li",[v._v("卷积过滤器零填充")])])]),v._v(" "),i("li",[v._v("掌握池化的计算过程原理")])])])},[],!1,null,null,null);_.default=t.exports}}]);